{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# 문제 3: Fashion MNIST 분류\n\n- **데이터셋**: PyTorch FashionMNIST (28x28 grayscale, 10 클래스)\n- **검증**: 반복 홀드아웃 10회, 훈련:검증:테스트 = 2:49:49\n- **평가**: Accuracy, F1 Score (Micro), F1 Score (Macro)\n\n## 모델 구조\n1. **LeNet-5** (베이스라인) - 수업시간에 배운 고전적 CNN\n2. **VGGNet-style** - 작은 3×3 커널을 깊게 쌓은 구조\n3. **ResNetCNN** - Residual Connection으로 깊은 학습\n4. **SEResNet** (최고 성능 예상) - SE attention + Residual\n\n## 평가 척도 설명\n- **Accuracy**: 전체 정확도\n- **F1 (Micro)**: 전체 TP/FP/FN 합산 후 계산 (= Accuracy, 균형 데이터에서)\n- **F1 (Macro)**: 클래스별 F1의 평균 (10개 클래스 각각의 성능 반영)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 라이브러리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------\n",
    "# 공용 라이브러리 및 유틸 불러오기\n",
    "# - torch/torchvision: 모델 정의, 데이터셋 로드, 변환\n",
    "# - sklearn: 데이터 분할 및 지표 계산\n",
    "# - matplotlib: 시각화 및 한글 폰트 설정\n",
    "# -------------------------------\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Subset, ConcatDataset\n",
    "from torch.amp import autocast, GradScaler  # Mixed Precision (새 API)\n",
    "from torchvision import datasets, transforms\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.font_manager as fm\n",
    "\n",
    "# 한글 폰트 설정 (Linux 서버 환경) - 라벨 깨짐 방지\n",
    "def set_korean_font():\n",
    "    \"\"\"시스템에서 사용 가능한 한글 폰트를 자동 설정\"\"\"\n",
    "    font_candidates = [\n",
    "        'NanumGothic', 'NanumBarunGothic', 'Malgun Gothic',\n",
    "        'AppleGothic', 'DejaVu Sans', 'Noto Sans CJK KR'\n",
    "    ]\n",
    "    available_fonts = [f.name for f in fm.fontManager.ttflist]\n",
    "    \n",
    "    for font in font_candidates:\n",
    "        if font in available_fonts:\n",
    "            plt.rcParams['font.family'] = font\n",
    "            plt.rcParams['axes.unicode_minus'] = False\n",
    "            print(f\"한글 폰트 설정: {font}\")\n",
    "            return\n",
    "    \n",
    "    print(\"한글 폰트를 찾지 못했습니다. 영문 라벨을 사용합니다.\")\n",
    "\n",
    "set_korean_font()\n",
    "\n",
    "# GPU 우선, Mac이면 MPS, 그 외 CPU 선택\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'mps' if torch.backends.mps.is_available() else 'cpu')\n",
    "print(f\"Device: {device}\")\n",
    "\n",
    "# GPU 정보 출력 (리포트용)\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------------------\n",
    "# H100 GPU 최적화 기본 설정 + 시드 고정 헬퍼\n",
    "# --------------------------------------------\n",
    "BATCH_SIZE = 256          # H100: 작은 이미지이므로 배치 확장\n",
    "NUM_WORKERS = 8           # 데이터 로딩 병렬화\n",
    "PIN_MEMORY = True         # GPU 메모리 전송 최적화\n",
    "USE_AMP = True            # Mixed Precision (BF16/FP16)\n",
    "\n",
    "def set_seed(seed):\n",
    "    \"\"\"torch/np 시드를 모두 고정하여 반복 홀드아웃 일관성 유지\"\"\"\n",
    "    torch.manual_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "# 고정 입력 크기에서 성능 향상\n",
    "torch.backends.cudnn.benchmark = True\n",
    "\n",
    "print(\"H100 최적화 설정:\")\n",
    "print(f\"  - Batch Size: {BATCH_SIZE}\")\n",
    "print(f\"  - Num Workers: {NUM_WORKERS}\")\n",
    "print(f\"  - Pin Memory: {PIN_MEMORY}\")\n",
    "print(f\"  - Mixed Precision (AMP): {USE_AMP}\")\n",
    "print(f\"  - cuDNN Benchmark: {torch.backends.cudnn.benchmark}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 데이터셋 다운로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------------------\n",
    "# Fashion MNIST 다운로드 및 기본 변환\n",
    "# - 흑백 이미지이므로 1채널 정규화 사용\n",
    "# --------------------------------------------\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.2860,), (0.3530,))\n",
    "])\n",
    "\n",
    "train_dataset = datasets.FashionMNIST(root='./data', train=True, download=True, transform=transform)\n",
    "test_dataset = datasets.FashionMNIST(root='./data', train=False, download=True, transform=transform)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 데이터 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------------------\n",
    "# 주어진 train/test를 합쳐서 다시 분할 (2:49:49)\n",
    "# --------------------------------------------\n",
    "full_dataset = ConcatDataset([train_dataset, test_dataset])\n",
    "print(f\"전체 데이터: {len(full_dataset)}\")\n",
    "\n",
    "# 레이블 추출 (ConcatDataset 내부 순회)\n",
    "all_labels = []\n",
    "for ds in full_dataset.datasets:\n",
    "    all_labels.extend(ds.targets.numpy())\n",
    "all_labels = np.array(all_labels)\n",
    "all_indices = np.arange(len(full_dataset))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------------------\n",
    "# 샘플 시각화 - 클래스 라벨 확인\n",
    "# --------------------------------------------\n",
    "class_names = ['T-shirt', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
    "               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n",
    "\n",
    "fig, axes = plt.subplots(2, 5, figsize=(12, 5))\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    img, label = train_dataset[i]\n",
    "    ax.imshow(img.squeeze(), cmap='gray')\n",
    "    ax.set_title(class_names[label])\n",
    "    ax.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 4. 모델 정의\n\n### 망 구조 표기법\n- **C**: Convolution (합성곱) - 공간적 특징 추출\n- **BN**: Batch Normalization - 학습 안정화, 수렴 가속\n- **R**: ReLU / **T**: Tanh - 활성화 함수\n- **AvgP** / **MaxP**: Average/Max Pooling - 다운샘플링\n- **GAP**: Global Average Pooling - 파라미터 감소\n- **D**: Dropout - 정규화, 과적합 방지\n- **FC**: Fully Connected - 분류를 위한 선형 변환\n- **Flat**: Flatten - 2D→1D 변환\n- **Res**: Residual Connection - skip connection\n- **SE**: Squeeze-and-Excitation - 채널별 attention\n\n---\n\n### 4.1 LeNet-5 (베이스라인, LeCun et al., 1998)\n\n**구조**: `C(1,6,5×5) → T → AvgP(2×2) → C(6,16,5×5) → T → AvgP(2×2) → Flat → FC(256,120) → T → FC(120,84) → T → FC(84,10)`\n\n**특징**:\n- 최초의 성공적인 CNN 구조 (수업시간에 배운 모델)\n- 5×5 큰 커널로 특징 추출\n- Average Pooling으로 다운샘플링\n- Tanh 활성화 함수 사용 (원본 논문)\n\n**효과/한계**:\n- ✅ CNN의 기본 원리 (합성곱 + 풀링) 적용\n- ✅ 공간적 특징 추출 가능\n- ❌ 얕은 구조로 복잡한 패턴 학습 제한\n- ❌ 현대적 기법(BN, ReLU, Dropout) 미적용"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeNet5(nn.Module):\n",
    "    \"\"\"\n",
    "    LeNet-5 (LeCun et al., 1998)\n",
    "    구조: C(1,6,5x5) → T → AvgP → C(6,16,5x5) → T → AvgP → Flat → FC → T → FC → T → FC\n",
    "    \"\"\"\n",
    "    def __init__(self, num_classes=10):\n",
    "        super().__init__()\n",
    "        self.layers = nn.ModuleList([\n",
    "            nn.Conv2d(1, 6, 5, 1, 2),         # C(1,6,5x5): 28x28 → 28x28\n",
    "            nn.Tanh(),                         # T: 활성화 (원본)\n",
    "            nn.AvgPool2d(2, 2),                # AvgP: 28x28 → 14x14\n",
    "            nn.Conv2d(6, 16, 5),               # C(6,16,5x5): 14x14 → 10x10\n",
    "            nn.Tanh(),                         # T: 활성화\n",
    "            nn.AvgPool2d(2, 2),                # AvgP: 10x10 → 5x5\n",
    "            nn.Flatten(),                      # Flat: (B,16,5,5) → (B,400)\n",
    "            nn.Linear(16 * 5 * 5, 120),        # FC(400,120)\n",
    "            nn.Tanh(),                         # T: 활성화\n",
    "            nn.Linear(120, 84),                # FC(120,84)\n",
    "            nn.Tanh(),                         # T: 활성화\n",
    "            nn.Linear(84, num_classes)         # FC(84,10): 출력층\n",
    "        ])\n",
    "    \n",
    "    def forward(self, x):\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "        return x\n",
    "\n",
    "print(\"LeNet-5: C(5x5) → T → AvgP → C(5x5) → T → AvgP → Flat → FC → T → FC → T → FC\")\n",
    "print(LeNet5())\n",
    "print(f\"파라미터: {sum(p.numel() for p in LeNet5().parameters()):,}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": "### 4.2 VGGNet-style (Simonyan & Zisserman, 2014)\n\n**구조**: `[C(3×3) → BN → R]×2 → MaxP → [C(3×3) → BN → R]×2 → MaxP → [C(3×3) → BN → R]×2 → GAP → D → FC`\n\n**특징**:\n- 작은 3×3 커널을 깊게 쌓음 (VGG의 핵심 아이디어)\n- 3×3 두 번 = 5×5 수용 영역, 파라미터는 더 적음\n- Batch Normalization + ReLU로 현대화\n- MaxPooling으로 다운샘플링\n\n**효과**:\n- ✅ 작은 커널로 파라미터 효율성 증가\n- ✅ 더 깊은 네트워크로 복잡한 패턴 학습\n- ✅ BN으로 학습 안정화\n- ⚠️ 깊은 구조로 gradient vanishing 가능성",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "class VGGBlock(nn.Module):\n",
    "    \"\"\"\n",
    "    VGG Block: 3x3 Conv를 여러 번 쌓은 블록\n",
    "    구조: [C(3x3) → BN → R] × n_convs\n",
    "    \"\"\"\n",
    "    def __init__(self, in_ch, out_ch, n_convs=2):\n",
    "        super().__init__()\n",
    "        layers = []\n",
    "        for i in range(n_convs):\n",
    "            layers.extend([\n",
    "                nn.Conv2d(in_ch if i == 0 else out_ch, out_ch, 3, 1, 1),\n",
    "                nn.BatchNorm2d(out_ch),\n",
    "                nn.ReLU()\n",
    "            ])\n",
    "        self.layers = nn.ModuleList(layers)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class VGGNet(nn.Module):\n",
    "    \"\"\"\n",
    "    VGGNet-style (Simonyan & Zisserman, 2014)\n",
    "    구조: VGGBlock×3 + MaxPool×2 + GAP + FC\n",
    "    \"\"\"\n",
    "    def __init__(self, num_classes=10):\n",
    "        super().__init__()\n",
    "        self.layers = nn.ModuleList([\n",
    "            VGGBlock(1, 32, n_convs=2),            # Block1: 28x28 → 28x28\n",
    "            nn.MaxPool2d(2, 2),                     # MaxP: 28 → 14\n",
    "            VGGBlock(32, 64, n_convs=2),           # Block2: 14x14 → 14x14\n",
    "            nn.MaxPool2d(2, 2),                     # MaxP: 14 → 7\n",
    "            VGGBlock(64, 128, n_convs=2),          # Block3: 7x7 → 7x7\n",
    "            nn.AdaptiveAvgPool2d(1),               # GAP: 7x7 → 1x1\n",
    "            nn.Dropout(0.5)\n",
    "        ])\n",
    "        self.fc = nn.Linear(128, num_classes)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        return self.fc(x)\n",
    "\n",
    "print(\"VGGNet: [C(3x3)→BN→R]×2 → MaxP → [C(3x3)→BN→R]×2 → MaxP → [C(3x3)→BN→R]×2 → GAP → D → FC\")\n",
    "print(VGGNet())\n",
    "print(f\"파라미터: {sum(p.numel() for p in VGGNet().parameters()):,}\")\n",
    "\n"
   ],
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### 4.3 ResNetCNN (He et al., 2015)\n\n**구조**: `C(1,32) → BN → R → [ResBlock(32,32)]×1 → [ResBlock(32,64)]×1 → [ResBlock(64,128)]×1 → GAP → D(0.5) → FC(128,10)`\n\n**ResBlock 내부**: `C(3×3) → BN → R → C(3×3) → BN → (+shortcut) → R`\n\n**특징**:\n- Residual Connection (skip connection) 도입\n- 입력을 출력에 더함: H(x) = F(x) + x\n- 잔차 F(x)를 학습하여 최적화 용이\n\n**효과**:\n- ✅ Skip connection으로 gradient flow 개선\n- ✅ Gradient vanishing 문제 해결\n- ✅ 매우 깊은 네트워크도 학습 가능\n- ✅ VGGNet보다 적은 파라미터로 더 좋은 성능"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualBlock(nn.Module):\n",
    "    \"\"\"\n",
    "    Residual Block (He et al., 2015)\n",
    "    구조: C → BN → R → C → BN → (+shortcut) → R\n",
    "    \"\"\"\n",
    "    def __init__(self, in_ch, out_ch, stride=1):\n",
    "        super().__init__()\n",
    "        self.layers = nn.ModuleList([\n",
    "            nn.Conv2d(in_ch, out_ch, 3, stride, 1, bias=False),\n",
    "            nn.BatchNorm2d(out_ch),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(out_ch, out_ch, 3, 1, 1, bias=False),\n",
    "            nn.BatchNorm2d(out_ch)\n",
    "        ])\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_ch != out_ch:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_ch, out_ch, 1, stride, bias=False),\n",
    "                nn.BatchNorm2d(out_ch)\n",
    "            )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = x\n",
    "        for layer in self.layers:\n",
    "            out = layer(out)\n",
    "        out += self.shortcut(x)\n",
    "        return nn.ReLU()(out)\n",
    "\n",
    "\n",
    "class ResNetCNN(nn.Module):\n",
    "    \"\"\"\n",
    "    ResNetCNN\n",
    "    구조: C(1,32) → BN → R → Res(32,32) → Res(32,64) → Res(64,128) → GAP → D → FC\n",
    "    \"\"\"\n",
    "    def __init__(self, num_classes=10):\n",
    "        super().__init__()\n",
    "        self.layers = nn.ModuleList([\n",
    "            nn.Conv2d(1, 32, 3, 1, 1, bias=False),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            ResidualBlock(32, 32, 1),\n",
    "            ResidualBlock(32, 64, 2),\n",
    "            ResidualBlock(64, 128, 2),\n",
    "            nn.AdaptiveAvgPool2d(1),\n",
    "            nn.Dropout(0.5)\n",
    "        ])\n",
    "        self.fc = nn.Linear(128, num_classes)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        return self.fc(x)\n",
    "\n",
    "print(\"ResNetCNN: C → BN → R → Res → Res → Res → GAP → D → FC\")\n",
    "print(ResNetCNN())\n",
    "print(f\"파라미터: {sum(p.numel() for p in ResNetCNN().parameters()):,}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### 4.4 SEResNet (Hu et al., 2017) - 최고 성능 예상\n\n**구조**: `C(1,32) → BN → R → [SEResBlock]×3 → GAP → D(0.5) → FC(128,10)`\n\n**SEResBlock 내부**: `C → BN → R → C → BN → SE → (+shortcut) → R`\n\n**SE Block**: `GAP → FC(C,C/16) → R → FC(C/16,C) → Sigmoid → Scale`\n- Squeeze: GAP로 채널별 전역 정보 압축\n- Excitation: FC로 채널 간 관계 학습 후 중요도 계산\n\n**특징**:\n- Squeeze-and-Excitation 메커니즘\n- 채널별 attention으로 중요한 특징 강조\n- 수업에서 다루지 않은 최신 구조\n\n**효과**:\n- ✅ 채널별 중요도를 동적으로 조절\n- ✅ 중요한 특징 채널 강조, 불필요한 채널 억제\n- ✅ 적은 파라미터 추가로 큰 성능 향상\n- ✅ Residual + Attention 시너지"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SEBlock(nn.Module):\n",
    "    \"\"\"\n",
    "    Squeeze-and-Excitation Block (Hu et al., 2017)\n",
    "    구조: GAP → FC(C, C/r) → R → FC(C/r, C) → Sigmoid → Scale\n",
    "    \"\"\"\n",
    "    def __init__(self, channels, reduction=16):\n",
    "        super().__init__()\n",
    "        self.layers = nn.ModuleList([\n",
    "            nn.AdaptiveAvgPool2d(1),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(channels, channels // reduction),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(channels // reduction, channels),\n",
    "            nn.Sigmoid()\n",
    "        ])\n",
    "    \n",
    "    def forward(self, x):\n",
    "        b, c, _, _ = x.size()\n",
    "        scale = x\n",
    "        for layer in self.layers:\n",
    "            scale = layer(scale)\n",
    "        scale = scale.view(b, c, 1, 1)\n",
    "        return x * scale\n",
    "\n",
    "\n",
    "class SEResidualBlock(nn.Module):\n",
    "    \"\"\"\n",
    "    SE-Residual Block\n",
    "    구조: C → BN → R → C → BN → SE → (+shortcut) → R\n",
    "    \"\"\"\n",
    "    def __init__(self, in_ch, out_ch, stride=1):\n",
    "        super().__init__()\n",
    "        self.layers = nn.ModuleList([\n",
    "            nn.Conv2d(in_ch, out_ch, 3, stride, 1, bias=False),\n",
    "            nn.BatchNorm2d(out_ch),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(out_ch, out_ch, 3, 1, 1, bias=False),\n",
    "            nn.BatchNorm2d(out_ch),\n",
    "            SEBlock(out_ch)\n",
    "        ])\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_ch != out_ch:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_ch, out_ch, 1, stride, bias=False),\n",
    "                nn.BatchNorm2d(out_ch)\n",
    "            )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = x\n",
    "        for layer in self.layers:\n",
    "            out = layer(out)\n",
    "        out += self.shortcut(x)\n",
    "        return nn.ReLU()(out)\n",
    "\n",
    "\n",
    "class SEResNet(nn.Module):\n",
    "    \"\"\"\n",
    "    SE-ResNet (Squeeze-and-Excitation ResNet)\n",
    "    구조: C(1,32) → BN → R → SERes(32,32) → SERes(32,64) → SERes(64,128) → GAP → D → FC\n",
    "    \"\"\"\n",
    "    def __init__(self, num_classes=10):\n",
    "        super().__init__()\n",
    "        self.layers = nn.ModuleList([\n",
    "            nn.Conv2d(1, 32, 3, 1, 1, bias=False),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            SEResidualBlock(32, 32, 1),\n",
    "            SEResidualBlock(32, 64, 2),\n",
    "            SEResidualBlock(64, 128, 2),\n",
    "            nn.AdaptiveAvgPool2d(1),\n",
    "            nn.Dropout(0.5)\n",
    "        ])\n",
    "        self.fc = nn.Linear(128, num_classes)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        return self.fc(x)\n",
    "\n",
    "print(\"SEResNet: C → BN → R → SERes → SERes → SERes → GAP → D → FC\")\n",
    "print(SEResNet())\n",
    "print(f\"파라미터: {sum(p.numel() for p in SEResNet().parameters()):,}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "# --------------------------------------------\n",
    "# ConvNeXt-Small (Fashion MNIST, 28x28 Gray)\n",
    "# - Depthwise 7x7 → LayerNorm → Pointwise 확장/축소 (GELU)\n",
    "# - 3-stage 경량 ConvNeXt: {2,2,6} 블록, 해상도 단계별 절반\n",
    "# --------------------------------------------\n",
    "class LayerNorm2d(nn.Module):\n",
    "    \"\"\"채널 기준 LayerNorm (ConvNeXt 스타일)\"\"\"\n",
    "    def __init__(self, num_channels, eps=1e-6):\n",
    "        super().__init__()\n",
    "        self.weight = nn.Parameter(torch.ones(num_channels))\n",
    "        self.bias = nn.Parameter(torch.zeros(num_channels))\n",
    "        self.eps = eps\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean = x.mean(dim=1, keepdim=True)\n",
    "        var = x.var(dim=1, keepdim=True, unbiased=False)\n",
    "        x = (x - mean) / torch.sqrt(var + self.eps)\n",
    "        return self.weight.view(1, -1, 1, 1) * x + self.bias.view(1, -1, 1, 1)\n",
    "\n",
    "\n",
    "class ConvNeXtBlock(nn.Module):\n",
    "    \"\"\"ConvNeXt Block: DWConv(7x7) → LN → PWConv×2 + GELU → LayerScale → Residual\"\"\"\n",
    "    def __init__(self, dim, layer_scale_init_value=1e-6):\n",
    "        super().__init__()\n",
    "        self.dwconv = nn.Conv2d(dim, dim, kernel_size=7, padding=3, groups=dim)\n",
    "        self.norm = LayerNorm2d(dim)\n",
    "        self.pwconv1 = nn.Conv2d(dim, 4 * dim, kernel_size=1)\n",
    "        self.act = nn.GELU()\n",
    "        self.pwconv2 = nn.Conv2d(4 * dim, dim, kernel_size=1)\n",
    "        self.gamma = nn.Parameter(layer_scale_init_value * torch.ones(dim)) if layer_scale_init_value > 0 else None\n",
    "\n",
    "    def forward(self, x):\n",
    "        shortcut = x\n",
    "        x = self.dwconv(x)\n",
    "        x = self.norm(x)\n",
    "        x = self.pwconv1(x)\n",
    "        x = self.act(x)\n",
    "        x = self.pwconv2(x)\n",
    "        if self.gamma is not None:\n",
    "            x = self.gamma.view(1, -1, 1, 1) * x\n",
    "        return shortcut + x\n",
    "\n",
    "\n",
    "class ConvNeXtSmallFashion(nn.Module):\n",
    "    \"\"\"\n",
    "    ConvNeXt-Small 변형 (28x28, 1채널)\n",
    "    구조: Stem(4x4,s4) → [Block×{2,2,6} + Downsample] → GAP → Dropout → FC\n",
    "    \"\"\"\n",
    "    def __init__(self, num_classes=10):\n",
    "        super().__init__()\n",
    "        depths = [2, 2, 6]\n",
    "        dims = [64, 128, 256]\n",
    "\n",
    "        self.downsample_layers = nn.ModuleList([\n",
    "            nn.Sequential(\n",
    "                nn.Conv2d(1, dims[0], kernel_size=4, stride=4),  # 28 → 7\n",
    "                LayerNorm2d(dims[0])\n",
    "            )\n",
    "        ])\n",
    "        for i in range(2):\n",
    "            self.downsample_layers.append(\n",
    "                nn.Sequential(\n",
    "                    LayerNorm2d(dims[i]),\n",
    "                    nn.Conv2d(dims[i], dims[i+1], kernel_size=2, stride=2)  # 7→4→2\n",
    "                )\n",
    "            )\n",
    "\n",
    "        self.stages = nn.ModuleList()\n",
    "        for i in range(3):\n",
    "            blocks = [ConvNeXtBlock(dims[i]) for _ in range(depths[i])]\n",
    "            self.stages.append(nn.ModuleList(blocks))\n",
    "\n",
    "        self.norm = LayerNorm2d(dims[-1])\n",
    "        self.head = nn.Linear(dims[-1], num_classes)\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.downsample_layers[0](x)\n",
    "        for i in range(3):\n",
    "            for block in self.stages[i]:\n",
    "                x = block(x)\n",
    "            if i < 2:\n",
    "                x = self.downsample_layers[i+1](x)\n",
    "        x = self.norm(x)\n",
    "        x = x.mean([-2, -1])\n",
    "        x = self.dropout(x)\n",
    "        return self.head(x)\n",
    "\n",
    "print(\"ConvNeXt-Small (Fashion): Stem(4x4,s4) → Blocks×{2,2,6} → GAP → D → FC\")\n",
    "print(ConvNeXtSmallFashion())\n",
    "print(f\"파라미터: {sum(p.numel() for p in ConvNeXtSmallFashion().parameters()):,}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 학습 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------------------\n",
    "# 학습/평가 유틸리티 함수 (H100 최적화)\n",
    "# --------------------------------------------\n",
    "scaler = GradScaler('cuda', enabled=USE_AMP)\n",
    "\n",
    "def train_epoch(model, loader, criterion, optimizer):\n",
    "    \"\"\"Mixed Precision 학습 (H100 최적화)\"\"\"\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for images, labels in loader:\n",
    "        images, labels = images.to(device, non_blocking=True), labels.to(device, non_blocking=True)\n",
    "        \n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "        \n",
    "        with autocast('cuda', enabled=USE_AMP):\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "        \n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        total_loss += loss.item()\n",
    "    return total_loss / len(loader)\n",
    "\n",
    "def evaluate(model, loader):\n",
    "    \"\"\"평가 함수 - Accuracy, F1 (Micro), F1 (Macro) 반환\"\"\"\n",
    "    model.eval()\n",
    "    preds, labels_list = [], []\n",
    "    with torch.no_grad():\n",
    "        for images, labels in loader:\n",
    "            images = images.to(device, non_blocking=True)\n",
    "            with autocast('cuda', enabled=USE_AMP):\n",
    "                outputs = model(images)\n",
    "            preds.extend(outputs.argmax(1).cpu().numpy())\n",
    "            labels_list.extend(labels.numpy())\n",
    "    \n",
    "    acc = accuracy_score(labels_list, preds)\n",
    "    f1_micro = f1_score(labels_list, preds, average='micro')\n",
    "    f1_macro = f1_score(labels_list, preds, average='macro')\n",
    "    return acc, f1_micro, f1_macro\n",
    "\n",
    "def train_model(model, train_loader, val_loader, epochs=20, lr=0.001):\n",
    "    \"\"\"H100 최적화 학습 함수\"\"\"\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=lr, weight_decay=0.01)\n",
    "    scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=epochs)\n",
    "    \n",
    "    best_acc = 0\n",
    "    best_state = None\n",
    "    patience = 0\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        train_epoch(model, train_loader, criterion, optimizer)\n",
    "        val_acc, _, _ = evaluate(model, val_loader)\n",
    "        scheduler.step()\n",
    "        \n",
    "        if val_acc > best_acc:\n",
    "            best_acc = val_acc\n",
    "            best_state = {k: v.cpu().clone() for k, v in model.state_dict().items()}\n",
    "            patience = 0\n",
    "        else:\n",
    "            patience += 1\n",
    "            if patience >= 7:\n",
    "                break\n",
    "    \n",
    "    if best_state:\n",
    "        model.load_state_dict(best_state)\n",
    "    return model\n",
    "\n",
    "print(\"H100 최적화 학습 함수 정의 완료\")\n",
    "print(\"  - F1 Score: Micro (=Accuracy) + Macro (10개 클래스별 평균)\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. 반복 홀드아웃 검증 (10회)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------------------\n",
    "# 반복 홀드아웃 실행 함수 (2:49:49 분할을 10회 반복)\n",
    "# --------------------------------------------\n",
    "def run_holdout(model_class, model_name, n_repeats=10):\n",
    "    \"\"\"H100 최적화 반복 홀드아웃\"\"\"\n",
    "    results = {'accuracy': [], 'f1_micro': [], 'f1_macro': []}\n",
    "    \n",
    "    print()\n",
    "    print('='*60)\n",
    "    print(model_name)\n",
    "    print('='*60)\n",
    "    \n",
    "    for i in range(n_repeats):\n",
    "        set_seed(42 + i)\n",
    "        \n",
    "        # 2:49:49 분할\n",
    "        train_idx, temp_idx = train_test_split(all_indices, test_size=0.98, stratify=all_labels, random_state=42+i)\n",
    "        val_idx, test_idx = train_test_split(temp_idx, test_size=0.5, stratify=all_labels[temp_idx], random_state=42+i)\n",
    "        \n",
    "        train_loader = DataLoader(\n",
    "            Subset(full_dataset, train_idx), \n",
    "            batch_size=BATCH_SIZE, \n",
    "            shuffle=True,\n",
    "            num_workers=NUM_WORKERS,\n",
    "            pin_memory=PIN_MEMORY,\n",
    "            drop_last=True\n",
    "        )\n",
    "        val_loader = DataLoader(\n",
    "            Subset(full_dataset, val_idx), \n",
    "            batch_size=BATCH_SIZE,\n",
    "            num_workers=NUM_WORKERS,\n",
    "            pin_memory=PIN_MEMORY\n",
    "        )\n",
    "        test_loader = DataLoader(\n",
    "            Subset(full_dataset, test_idx), \n",
    "            batch_size=BATCH_SIZE,\n",
    "            num_workers=NUM_WORKERS,\n",
    "            pin_memory=PIN_MEMORY\n",
    "        )\n",
    "        \n",
    "        model = model_class().to(device)\n",
    "        \n",
    "        if hasattr(torch, 'compile'):\n",
    "            try:\n",
    "                model = torch.compile(model, mode='reduce-overhead')\n",
    "            except:\n",
    "                pass\n",
    "        \n",
    "        model = train_model(model, train_loader, val_loader, epochs=30)\n",
    "        \n",
    "        acc, f1_micro, f1_macro = evaluate(model, test_loader)\n",
    "        results['accuracy'].append(acc)\n",
    "        results['f1_micro'].append(f1_micro)\n",
    "        results['f1_macro'].append(f1_macro)\n",
    "        print(f\"[{i+1}/{n_repeats}] Acc: {acc:.4f}, F1(Micro): {f1_micro:.4f}, F1(Macro): {f1_macro:.4f}\")\n",
    "        \n",
    "        del model\n",
    "        torch.cuda.empty_cache() if torch.cuda.is_available() else None\n",
    "    \n",
    "    return results\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "lenet_results = run_holdout(LeNet5, \"LeNet-5 (베이스라인)\")"
  },
  {
   "cell_type": "code",
   "source": "vgg_results = run_holdout(VGGNet, \"VGGNet-style\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet_results = run_holdout(ResNetCNN, \"ResNetCNN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "senet_results = run_holdout(SEResNet, \"SEResNet (최고 성능)\")"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "convnext_results = run_holdout(ConvNeXtSmallFashion, \"ConvNeXt-Small (고성능)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. 결과 분석"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_summary(results, name):\n",
    "    # 평균/표준편차를 빠르게 확인하기 위한 헬퍼\n",
    "    acc_mean, acc_std = np.mean(results['accuracy']), np.std(results['accuracy'])\n",
    "    f1_micro_mean, f1_micro_std = np.mean(results['f1_micro']), np.std(results['f1_micro'])\n",
    "    f1_macro_mean, f1_macro_std = np.mean(results['f1_macro']), np.std(results['f1_macro'])\n",
    "    print(name)\n",
    "    print(f\"  Accuracy:    {acc_mean:.4f} ± {acc_std:.4f}\")\n",
    "    print(f\"  F1 (Micro):  {f1_micro_mean:.4f} ± {f1_micro_std:.4f}\")\n",
    "    print(f\"  F1 (Macro):  {f1_macro_mean:.4f} ± {f1_macro_std:.4f}\")\n",
    "    return acc_mean, acc_std, f1_micro_mean, f1_micro_std, f1_macro_mean, f1_macro_std\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"Final Results\")\n",
    "print(\"=\"*60)\n",
    "lenet_stats = print_summary(lenet_results, \"LeNet-5\")\n",
    "vgg_stats = print_summary(vgg_results, \"VGGNet\")\n",
    "resnet_stats = print_summary(resnet_results, \"ResNetCNN\")\n",
    "senet_stats = print_summary(senet_results, \"SEResNet\")\n",
    "convnext_stats = print_summary(convnext_results, \"ConvNeXt-Small\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------------------\n",
    "# 시각화 - Accuracy/F1 평균과 반복별 F1(Macro) 비교\n",
    "# --------------------------------------------\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "models = ['LeNet-5', 'VGGNet', 'ResNetCNN', 'SEResNet', 'ConvNeXt']\n",
    "all_results = [lenet_results, vgg_results, resnet_results, senet_results, convnext_results]\n",
    "colors = ['#ff9999', '#66b3ff', '#99ff99', '#ffcc99', '#c2a3ff']\n",
    "\n",
    "# Accuracy\n",
    "acc_means = [np.mean(r['accuracy']) for r in all_results]\n",
    "acc_stds = [np.std(r['accuracy']) for r in all_results]\n",
    "axes[0].bar(models, acc_means, yerr=acc_stds, capsize=5, color=colors)\n",
    "axes[0].set_title('Test Accuracy')\n",
    "axes[0].set_ylim([0.7, 1.0])\n",
    "axes[0].set_ylabel('Score')\n",
    "\n",
    "# F1 (Macro)\n",
    "f1_macro_means = [np.mean(r['f1_macro']) for r in all_results]\n",
    "f1_macro_stds = [np.std(r['f1_macro']) for r in all_results]\n",
    "axes[1].bar(models, f1_macro_means, yerr=f1_macro_stds, capsize=5, color=colors)\n",
    "axes[1].set_title('Test F1 Score (Macro)')\n",
    "axes[1].set_ylim([0.7, 1.0])\n",
    "axes[1].set_ylabel('Score')\n",
    "\n",
    "plt.suptitle('Fashion MNIST - Model Performance Comparison', fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 반복별 성능 비교\n",
    "fig, ax = plt.subplots(figsize=(14, 5))\n",
    "x = np.arange(10)\n",
    "width = 0.16\n",
    "\n",
    "ax.bar(x - 2*width, lenet_results['f1_macro'], width, label='LeNet-5', color='#ff9999')\n",
    "ax.bar(x - width, vgg_results['f1_macro'], width, label='VGGNet', color='#66b3ff')\n",
    "ax.bar(x, resnet_results['f1_macro'], width, label='ResNetCNN', color='#99ff99')\n",
    "ax.bar(x + width, senet_results['f1_macro'], width, label='SEResNet', color='#ffcc99')\n",
    "ax.bar(x + 2*width, convnext_results['f1_macro'], width, label='ConvNeXt', color='#c2a3ff')\n",
    "\n",
    "ax.set_xlabel('Iteration')\n",
    "ax.set_ylabel('F1 Score (Macro)')\n",
    "ax.set_title('Fashion MNIST - F1 (Macro) by Iteration')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels([f'{i+1}' for i in x])\n",
    "ax.legend()\n",
    "ax.set_ylim([0.7, 1.0])\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 8. 결론\n\n| 모델 | 구조 특징 | Accuracy | F1 (Micro) | F1 (Macro) |\n|------|----------|----------|------------|------------|\n| LeNet-5 | C(5×5)-AvgP-C(5×5)-AvgP-FC | - | - | - |\n| VGGNet | [C(3×3)]×2-MaxP 반복 | - | - | - |\n| ResNetCNN | Residual Connection | - | - | - |\n| SEResNet | SE Attention + Residual | - | - | - |\n\n### 평가 척도 해석\n- **F1 (Micro)**: 전체 샘플에 대해 TP/FP/FN을 합산하여 계산. 균형 데이터셋에서는 Accuracy와 동일.\n- **F1 (Macro)**: 각 클래스별 F1을 계산 후 평균. 10개 클래스 각각의 성능을 균등하게 반영.\n\n### 모델별 분석\n\n- **LeNet-5 (베이스라인)**: 1998년 고전적 구조. 5×5 큰 커널과 Tanh 활성화. 얕은 구조로 복잡한 패턴 학습에 한계.\n\n- **VGGNet-style**: 3×3 작은 커널을 깊게 쌓아 수용 영역 확보. BN과 ReLU로 현대화했으나 skip connection 없이 깊은 네트워크는 학습 어려움.\n\n- **ResNetCNN**: Residual Connection으로 gradient vanishing 해결. 입력을 출력에 더해 잔차 학습. 깊은 네트워크도 안정적 학습.\n\n- **SEResNet**: SE Block으로 채널별 중요도 동적 조절. 의류 분류에서 색상, 패턴, 질감 등 중요한 특징 채널에 집중. Residual + Attention 시너지로 최고 성능 예상."
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}